{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PVML SDK Comprehensive Example\n",
    "\n",
    "This notebook demonstrates a complete workflow using the PVML SDK, showcasing:\n",
    "\n",
    "1. **Environment Setup** - Loading configuration from .env.local\n",
    "2. **Client Initialization** - Setting up the PVML client\n",
    "3. **Workspace Management** - Working with workspaces and users\n",
    "4. **Data Source Integration** - Connecting to databases\n",
    "5. **AI Agent Creation** - Building and configuring AI agents\n",
    "6. **MCP Integration** - Working with Model Context Protocol\n",
    "7. **Interactive Queries** - Running queries through agents\n",
    "8. **Session Management** - Managing conversation sessions\n",
    "9. **Monitoring & Audit** - Tracking usage and performance\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "- PVML SDK installed (`pip install -r requirements.txt`)\n",
    "- A `.env.local` file with your PVML credentials\n",
    "- Access to a PVML workspace\n",
    "- Optional: A database for data source examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup and Configuration\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Load environment variables from .env.local\n",
    "def load_env_variables(env_file: str = \".env.local\") -> bool:\n",
    "    \"\"\"Load environment variables from .env.local file using python-dotenv\"\"\"\n",
    "    env_path = Path(env_file)\n",
    "    \n",
    "    if not env_path.exists():\n",
    "        print(f\"Warning: {env_file} not found. Please create it with your PVML credentials.\")\n",
    "        print(\"\\nRequired format:\")\n",
    "        print(\"PVML_API_KEY=your_api_key_here\")\n",
    "        print(\"PVML_API_URL=your_api_url_here\") \n",
    "        print(\"GPT_KEY=your_gpt_key_here\")\n",
    "        print(\"PVML_WORKSPACE_ID=your_workspace_id_here\")\n",
    "        print(\"PVML_DATASOURCE_ID=your_datasource_id_here\")\n",
    "        return False\n",
    "    \n",
    "    # Load environment variables from .env.local\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"Environment variables loaded from {env_file}\")\n",
    "    return True\n",
    "\n",
    "# Load environment variables\n",
    "env_loaded = load_env_variables()\n",
    "\n",
    "# Validate required environment variables\n",
    "required_vars = [\"PVML_API_KEY\", \"PVML_API_URL\", \"GPT_KEY\", \"PVML_WORKSPACE_ID\", \"PVML_DATASOURCE_ID\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    raise ValueError(f\"Missing required environment variables: {missing_vars}\")\n",
    "\n",
    "print(\"All required environment variables loaded successfully\")\n",
    "print(f\"API URL: {os.getenv('PVML_API_URL')}\")\n",
    "print(f\"Workspace ID: {os.getenv('PVML_WORKSPACE_ID')}\")\n",
    "print(f\"Datasource ID: {os.getenv('PVML_DATASOURCE_ID')}\")\n",
    "\n",
    "print(f\"\\nConfiguration loaded at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PVML SDK and Initialize Client\n",
    "from pvml import Client, Workspace, Agent, Datasource, LLM\n",
    "\n",
    "# Initialize PVML client\n",
    "def initialize_pvml_client() -> Client:\n",
    "    \"\"\"Initialize and return PVML client\"\"\"\n",
    "    api_key = os.environ.get(\"PVML_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"PVML_API_KEY not found in environment variables\")\n",
    "\n",
    "    client = Client(api_key=api_key)\n",
    "    print(\"PVML client initialized successfully\")\n",
    "    return client\n",
    "\n",
    "# Initialize client\n",
    "pvml_client = initialize_pvml_client()\n",
    "print(\"Client ready for use\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace Discovery and Connection\n",
    "def get_workspace() -> Workspace:\n",
    "    \"\"\"Get the target workspace\"\"\"\n",
    "    workspace_id = os.environ.get(\"PVML_WORKSPACE_ID\")\n",
    "    if not workspace_id:\n",
    "        print(\"PVML_WORKSPACE_ID not found in environment variables\")\n",
    "        print(\"Available workspaces:\")\n",
    "        workspaces = pvml_client.get_workspaces()\n",
    "        for ws_id, workspace in workspaces.items():\n",
    "            print(f\"  ID: {ws_id}, Name: {workspace.name}\")\n",
    "        raise ValueError(\"PVML_WORKSPACE_ID not found in environment variables\")\n",
    "    \n",
    "    # Get specific workspace\n",
    "    workspace = pvml_client.get_workspace(workspace_id)\n",
    "    print(f\"Connected to workspace: {workspace.name}\")\n",
    "    print(f\"Workspace ID: {workspace.id}\")\n",
    "    print(f\"Description: {workspace.description}\")\n",
    "    \n",
    "    return workspace\n",
    "\n",
    "# Connect to workspace\n",
    "workspace = get_workspace()\n",
    "\n",
    "# Get current user info\n",
    "current_user = workspace.get_current_user()\n",
    "print(f\"\\nCurrent user: {current_user.email}\")\n",
    "print(f\"User role: {current_user.role}\")\n",
    "print(f\"User type: {current_user.user_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Source Management\n",
    "def get_datasource() -> Datasource:\n",
    "    \"\"\"Get the target datasource\"\"\"\n",
    "    datasource_id = os.environ.get(\"PVML_DATASOURCE_ID\")\n",
    "    if not datasource_id:\n",
    "        print(\"PVML_DATASOURCE_ID not found in environment variables\")\n",
    "        print(\"Available datasources:\")\n",
    "        datasources = workspace.get_datasources()\n",
    "        for ds_id, datasource in datasources.items():\n",
    "            print(f\"  ID: {ds_id}, Name: {datasource.name}, Type: {datasource.type}\")\n",
    "        raise ValueError(\"PVML_DATASOURCE_ID not found in environment variables\")\n",
    "    \n",
    "    # Get specific datasource\n",
    "    datasource = workspace.get_datasource(datasource_id)\n",
    "    print(f\"Connected to datasource: {datasource.name}\")\n",
    "    print(f\"Datasource ID: {datasource.id}\")\n",
    "    print(f\"Type: {datasource.type}\")\n",
    "    print(f\"Description: {datasource.description}\")\n",
    "    \n",
    "    # Test datasource connection\n",
    "    ping_result = datasource.ping()\n",
    "    print(f\"Connection test: {ping_result}\")\n",
    "    \n",
    "    return datasource\n",
    "\n",
    "# Connect to datasource\n",
    "datasource = get_datasource()\n",
    "\n",
    "# Get datasource schema information\n",
    "print(\"\\nDatasource Schema Information:\")\n",
    "schemas_tree = datasource.get_schemas_tree()\n",
    "print(f\"Available schemas: {len(schemas_tree)}\")\n",
    "\n",
    "# Display first few schemas\n",
    "for i, schema_info in enumerate(schemas_tree):\n",
    "    if i >= 3:  # Limit output\n",
    "        print(f\"... and {len(schemas_tree) - 3} more schemas\")\n",
    "        break\n",
    "    schema_name = schema_info.get('schemaName', f'Schema {i+1}')\n",
    "    print(f\"  Schema: {schema_name}\")\n",
    "    if 'tables' in schema_info:\n",
    "        table_count = len(schema_info['tables'])\n",
    "        print(f\"    Tables: {table_count}\")\n",
    "    # Show additional schema info if available\n",
    "    if 'description' in schema_info:\n",
    "        print(f\"    Description: {schema_info['description']}\")\n",
    "    if 'type' in schema_info:\n",
    "        print(f\"    Type: {schema_info['type']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Access Permission Setup\n",
    "from pvml.policy import PolicyType\n",
    "import json\n",
    "\n",
    "def setup_full_access_permission():\n",
    "    \"\"\"Set up full access permission for the current user on the datasource\"\"\"\n",
    "    print(\"Setting up full access permissions...\")\n",
    "    \n",
    "    # Get current user\n",
    "    current_user = workspace.get_current_user()\n",
    "    print(f\"Current user: {current_user.email}\")\n",
    "    \n",
    "    # Create a full access policy for all schemas\n",
    "    # This creates a data access policy that grants access to all schemas\n",
    "    policy_data = [{\"schema\":\"*\",\"table\":\"*\",\"column\":\"*\"}]\n",
    "    \n",
    "    \n",
    "    full_access_policy = datasource.create_policy(\n",
    "        name=\"Full Access Policy\",\n",
    "        description=\"Complete access to all data in the datasource\",\n",
    "        policy_type=PolicyType.DATA_ACCESS,\n",
    "        data=json.dumps(policy_data)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCreated full access policy:\")\n",
    "    print(f\"Policy ID: {full_access_policy.id}\")\n",
    "    print(f\"Name: {full_access_policy.name}\")\n",
    "    print(f\"Type: {full_access_policy.type}\")\n",
    "    print(f\"Description: {full_access_policy.description}\")\n",
    "    print(f\"Data: {full_access_policy.data}\")\n",
    "    \n",
    "    return full_access_policy\n",
    "\n",
    "# Setup full access permission\n",
    "policy = setup_full_access_permission()\n",
    "print(f\"\\nFull access policy ready: {policy.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Creation and Policy Assignment\n",
    "def create_view_with_policy():\n",
    "    \"\"\"Create a view associated with the datasource and assign the policy\"\"\"\n",
    "    print(\"Creating view with policy assignment...\")\n",
    "    \n",
    "    # Create a view for the datasource\n",
    "    view = workspace.create_view(\n",
    "        name=\"Data Analysis View\",\n",
    "        description=\"Comprehensive view for data analysis with full access permissions\",\n",
    "        datasource_id=datasource.id\n",
    "    )\n",
    "    \n",
    "    print(f\"Created view: {view.name}\")\n",
    "    print(f\"View ID: {view.id}\")\n",
    "    print(f\"Datasource ID: {view.datasource_id}\")\n",
    "    print(f\"Description: {view.description}\")\n",
    "    \n",
    "    # Assign the full access policy to the view\n",
    "    print(f\"\\nAssigning policy to view...\")\n",
    "    view.update_policies(policy_ids_to_add=[policy.id])\n",
    "    print(f\"Policy '{policy.name}' assigned to view '{view.name}'\")\n",
    "    \n",
    "    # Get current user and assign them to the view\n",
    "    current_user = workspace.get_current_user()\n",
    "    print(f\"\\nAssigning current user to view...\")\n",
    "    view.update_entities(entities_to_add=[current_user])\n",
    "    print(f\"User '{current_user.email}' assigned to view '{view.name}'\")\n",
    "    \n",
    "    # Verify the view setup\n",
    "    print(f\"\\nView setup verification:\")\n",
    "    view_policies = view.get_policies()\n",
    "    print(f\"View has {len(view_policies)} policies assigned:\")\n",
    "    for policy_id, assigned_policy in view_policies.items():\n",
    "        print(f\"  - {assigned_policy.name} (ID: {policy_id})\")\n",
    "    \n",
    "    view_entities = view.get_entities()\n",
    "    print(f\"View has {len(view_entities)} entities assigned:\")\n",
    "    for entity_id, entity in view_entities.items():\n",
    "        print(f\"  - {entity.entity_type.value} (ID: {entity_id})\")\n",
    "    \n",
    "    return view\n",
    "\n",
    "# Create view with policy\n",
    "view = create_view_with_policy()\n",
    "print(f\"\\nView ready for data analysis: {view.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP Retrieval\n",
    "def get_view_mcp(_view_name: str):\n",
    "    \"\"\"Retrieve the MCP created with the same name as the view\"\"\"\n",
    "    print(f\"Retrieving MCP associated with view '{_view_name}'...\")\n",
    "    \n",
    "    # Get all MCPs in the workspace\n",
    "    all_mcps = workspace.get_mcps()\n",
    "    print(f\"Found {len(all_mcps)} MCPs in workspace\")\n",
    "    \n",
    "    # Look for MCP with the same name as the view\n",
    "    view_mcp = None\n",
    "    for mcp_id, mcp in all_mcps.items():\n",
    "        print(f\"  MCP: {mcp.name} (ID: {mcp_id})\")\n",
    "        if mcp.name == _view_name:\n",
    "            view_mcp = mcp\n",
    "            print(f\"    -> Found matching MCP for view!\")\n",
    "            break\n",
    "    \n",
    "    if not view_mcp:\n",
    "        print(f\"No MCP found with name '{_view_name}'\")\n",
    "        print(\"Available MCPs:\")\n",
    "        for mcp_id, mcp in all_mcps.items():\n",
    "            print(f\"  - {mcp.name} (ID: {mcp_id})\")\n",
    "        raise ValueError(f\"MCP with name '{_view_name}' not found\")\n",
    "    \n",
    "    print(f\"\\nRetrieved MCP: {view_mcp.name}\")\n",
    "    print(f\"MCP ID: {view_mcp.id}\")\n",
    "    print(f\"MCP Type: {view_mcp.type}\")\n",
    "    print(f\"MCP URL: {view_mcp.url}\")\n",
    "    print(f\"Description: {view_mcp.description}\")\n",
    "    print(f\"Created by: {view_mcp.created_by}\")\n",
    "    print(f\"Created at: {view_mcp.created_at}\")\n",
    "    \n",
    "    return view_mcp\n",
    "\n",
    "# Retrieve the MCP using the view name\n",
    "mcp = get_view_mcp(view.name)\n",
    "print(f\"\\nMCP ready: {mcp.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s['schemaName'] for s in view.get_view_tree()['schemas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Configuration and Management\n",
    "def setup_llm() -> LLM:\n",
    "    \"\"\"Set up an LLM\"\"\"\n",
    "    \n",
    "    # Create new LLM if we have GPT_KEY\n",
    "    gpt_key = os.environ.get(\"GPT_KEY\")\n",
    "    if not gpt_key:\n",
    "        raise ValueError(\"No GPT_KEY provided\")\n",
    "    basic_props = LLM.create_basic_props(\n",
    "        temperature=0.3\n",
    "    )\n",
    "    print(\"Creating new GPT LLM...\")\n",
    "    llm = workspace.create_llm(\n",
    "        name=\"GPT-4 LLM\",\n",
    "        description=\"OpenAI GPT-4 model for AI agent interactions\",\n",
    "        vendor_name=\"openAi\",\n",
    "        model_name=\"gpt-4o-2024-11-20\",\n",
    "        token=gpt_key,\n",
    "        props=basic_props\n",
    "    )\n",
    "    print(f\"Created new LLM: {llm.name}\")\n",
    "    return llm\n",
    "\n",
    "# Setup LLM\n",
    "llm = setup_llm()\n",
    "\n",
    "print(f\"\\nLLM ready: {llm.name}\")\n",
    "print(f\"Vendor: {llm.vendor_name}\")\n",
    "print(f\"Model: {llm.model_name}\")\n",
    "props = llm.props\n",
    "print(f\"Configuration: {props}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Creation and Configuration\n",
    "from pvml import MCP\n",
    "\n",
    "def create_data_agent(_llm: LLM, _mcp: MCP) -> Agent:\n",
    "    \"\"\"Create a comprehensive data analysis agent with MCP access\"\"\"\n",
    "    # Define agent prompt\n",
    "    agent_prompt = pvml_client.get_default_prompts()['prompt']\n",
    "\n",
    "    \n",
    "    # Create agent with MCP access\n",
    "    agent = workspace.create_agent(\n",
    "        name=\"Data Analysis Agent\",\n",
    "        description=\"Comprehensive data analysis and reporting agent with database access via MCP\",\n",
    "        prompt=agent_prompt,\n",
    "        llm_id=_llm.id,\n",
    "        mcp_ids=[_mcp.id]  # Add the retrieved MCP\n",
    "    )\n",
    "    \n",
    "    print(f\"Created agent: {agent.name}\")\n",
    "    print(f\"Agent ID: {agent.id}\")\n",
    "    print(f\"LLM ID: {agent.llm_id}\")\n",
    "    print(f\"MCP IDs: {agent.mcp_ids}\")\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# Create agent with LLM and MCP\n",
    "agent = create_data_agent(llm, mcp)\n",
    "\n",
    "print(f\"\\nAgent ready: {agent.name}\")\n",
    "print(f\"Description: {agent.description}\")\n",
    "\n",
    "# Get agent details\n",
    "agent_details = workspace.get_agent(agent.id)\n",
    "print(f\"Created by: {agent_details.created_by}\")\n",
    "print(f\"Creation time: {agent_details.creation_time}\")\n",
    "\n",
    "# Verify MCP assignment\n",
    "# Verify MCP assignment and permissions\n",
    "# permitted_mcps = workspace.get_permitted_mcps()\n",
    "# print(f\"Permitted MCPs: {permitted_mcps}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Query Examples\n",
    "def run_sample_queries():\n",
    "    \"\"\"Run sample queries through the agent\"\"\"\n",
    "    # Sample queries to demonstrate capabilities\n",
    "    sample_queries = [\n",
    "        \"how many accounts do we have, retrieve single column named count\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Running sample queries...\\n\")\n",
    "    \n",
    "    for i, query in enumerate(sample_queries, 1):\n",
    "        print(f\"Query {i}: {query}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Generate response using the agent\n",
    "        response = agent.generate(query)\n",
    "        print(f\"Response: {response}\")\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Run sample queries\n",
    "run_sample_queries()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Management\n",
    "def demonstrate_session_management():\n",
    "    \"\"\"Demonstrate agent session management for conversation continuity\"\"\"\n",
    "    # Start a new session\n",
    "    session = agent.start_session(\"Data Analysis Session\")\n",
    "    print(f\"Started new session: {session.title}\")\n",
    "    print(f\"Session ID: {session.id}\")\n",
    "    print(f\"Agent ID: {session.agent_id}\")\n",
    "    \n",
    "    # Have a conversation with context\n",
    "    conversation_queries = [\n",
    "        \"how many accounts do we have, retrieve single column named count\",\n",
    "        # \"accounts look at column account_id\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nStarting conversation with context...\")\n",
    "    \n",
    "    for i, query in enumerate(conversation_queries, 1):\n",
    "        print(f\"\\nQuery {i}: {query}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Generate response in session context\n",
    "        response = session.generate(query)\n",
    "        print(f\"Response: {response}\")\n",
    "    \n",
    "    # Get session details\n",
    "    print(f\"\\nSession Summary:\")\n",
    "    print(f\"Title: {session.title}\")\n",
    "    print(f\"Messages exchanged: {len(session.messages) if hasattr(session, 'messages') else 'N/A'}\")\n",
    "    print(f\"Last modified: {session.last_modified}\")\n",
    "    \n",
    "    return session\n",
    "\n",
    "# Demonstrate session management\n",
    "session = demonstrate_session_management()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring and Audit\n",
    "def demonstrate_monitoring():\n",
    "    \"\"\"Demonstrate monitoring and audit capabilities\"\"\"\n",
    "    print(\"Querying audit logs...\")\n",
    "    \n",
    "    # Get query audit information\n",
    "    audit_results = workspace.get_query_audit(\n",
    "        page_size=10,\n",
    "        page_number=1\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(audit_results)} audit records\")\n",
    "    \n",
    "    # Display audit information\n",
    "    for i, audit_record in enumerate(audit_results[:5], 1):  # Show first 5 records\n",
    "        print(f\"\\nAudit Record {i}:\")\n",
    "        print(f\"  Query: {audit_record.get('query', 'N/A')}\")\n",
    "        print(f\"  User: {audit_record.get('userEmail', 'N/A')}\")\n",
    "        print(f\"  User Question: {audit_record.get('userQuestion', 'N/A')}\")\n",
    "        print(f\"  Duration: {audit_record.get('duration', 'N/A') /1000:.2f} s\")\n",
    "        print(f\"  Status: {audit_record.get('status', 'N/A')}\")\n",
    "        print(f\"  Error Type: {audit_record.get('errorType', 'N/A')}\")\n",
    "\n",
    "    if len(audit_results) > 5:\n",
    "        print(f\"\\n... and {len(audit_results) - 5} more records\")\n",
    "    \n",
    "    return audit_results\n",
    "\n",
    "# Demonstrate monitoring\n",
    "audit_data = demonstrate_monitoring()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
